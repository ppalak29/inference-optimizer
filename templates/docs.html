<!DOCTYPE html>
<html>
<head>
    <title>Documentation - Inference Optimizer</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Arial;
            background: #f5f5f5;
            padding: 40px 20px;
        }
        .nav {
            text-align: center;
            margin-bottom: 40px;
        }
        .nav a {
            color: #667eea;
            text-decoration: none;
            margin: 0 15px;
            font-weight: 500;
        }
        .container {
            max-width: 900px;
            margin: 0 auto;
            background: white;
            padding: 60px;
            border-radius: 12px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            margin-bottom: 30px;
            border-bottom: 3px solid #667eea;
            padding-bottom: 15px;
        }
        h2 {
            color: #667eea;
            margin-top: 40px;
            margin-bottom: 20px;
        }
        h3 {
            color: #333;
            margin-top: 30px;
            margin-bottom: 15px;
        }
        p {
            color: #666;
            line-height: 1.8;
            margin-bottom: 15px;
        }
        code {
            background: #f5f5f5;
            padding: 2px 8px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            color: #e91e63;
        }
        pre {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
        }
        .feature-list {
            list-style: none;
            padding: 0;
        }
        .feature-list li {
            padding: 10px 0;
            padding-left: 30px;
            position: relative;
        }
        .feature-list li:before {
            content: "‚úì";
            position: absolute;
            left: 0;
            color: #4CAF50;
            font-weight: bold;
            font-size: 20px;
        }
        .warning {
            background: #fff3e0;
            padding: 15px;
            border-radius: 8px;
            border-left: 4px solid #ff9800;
            margin: 20px 0;
        }
        .warning strong {
            color: #e65100;
        }
        .step {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
            border-left: 4px solid #667eea;
        }
        .step-number {
            display: inline-block;
            background: #667eea;
            color: white;
            width: 30px;
            height: 30px;
            border-radius: 50%;
            text-align: center;
            line-height: 30px;
            font-weight: bold;
            margin-right: 10px;
        }
    </style>
</head>
<body>
    <div class="nav">
        <a href="/">‚Üê Home</a>
        <a href="/analyze">Analyze</a>
        <a href="/live">Live Dashboard</a>
        <a href="/docs">Docs</a>
    </div>
    
    <div class="container">
        <h1>üìñ Integration Guide</h1>
        
        <p>
            Inference Optimizer is a drop-in proxy that reduces your OpenAI API costs through
            intelligent caching, model routing, and optimization. Integration takes less than 5 minutes.
        </p>
        
        <h2>‚ú® Features</h2>
        <ul class="feature-list">
            <li><strong>Automatic Caching:</strong> Duplicate requests are served from cache (0 cost)</li>
            <li><strong>Smart Model Routing:</strong> Simple queries automatically use GPT-3.5 instead of GPT-4 (90% cheaper)</li>
            <li><strong>Zero Code Changes:</strong> Works with existing OpenAI SDK code</li>
            <li><strong>Real-time Dashboard:</strong> Track savings and performance live</li>
        </ul>
        
        <h2>üöÄ Quick Start</h2>
        <div class="warning">
            <strong>üîí Privacy:</strong> Your API data is processed in-memory only. 
            We don't store prompts, responses, or any customer data. The proxy is stateless 
            except for Redis cache (which you control and can clear anytime).
        </div>
        <div class="step">
            <h3><span class="step-number">1</span> Start the Proxy</h3>
            <pre>cd proxy
export OPENAI_API_KEY="sk-your-key-here"
export MOCK_MODE=false
python proxy.py</pre>
            <p>The proxy will run on <code>http://localhost:8000</code></p>
        </div>
        
        <div class="step">
            <h3><span class="step-number">2</span> Update Your Code (One Line)</h3>
            <p><strong>Before:</strong></p>
            <pre>from openai import OpenAI

client = OpenAI(
    api_key="sk-your-key"
)

response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "Hello!"}]
)</pre>
            
            <p><strong>After:</strong></p>
            <pre>from openai import OpenAI

client = OpenAI(
    api_key="sk-anything",  # Proxy handles real key
    base_url="http://localhost:8000/v1"  # ‚Üê ADD THIS LINE
)

response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "Hello!"}]
)</pre>
        </div>
        
        <div class="step">
            <h3><span class="step-number">3</span> Watch Savings Accumulate</h3>
            <p>Visit <a href="/live" style="color: #667eea;">the live dashboard</a> to see real-time metrics:</p>
            <ul class="feature-list">
                <li>Requests processed</li>
                <li>Cache hit rate</li>
                <li>Model downgrades</li>
                <li>Total savings ($)</li>
            </ul>
        </div>
        
        <h2>‚öôÔ∏è Configuration</h2>
        
        <h3>Environment Variables</h3>
        <pre>OPENAI_API_KEY=sk-...     # Your OpenAI API key
MOCK_MODE=false           # Use real OpenAI (true for testing)
REDIS_HOST=localhost      # Redis host (optional)
REDIS_PORT=6379          # Redis port (optional)</pre>
        
        <h3>Requirements</h3>
        <ul class="feature-list">
            <li>Python 3.8+</li>
            <li>Redis (for caching)</li>
            <li>OpenAI Python SDK v1.0+</li>
        </ul>
        
        <h2>üìä How It Works</h2>
        
        <h3>1. Caching</h3>
        <p>
            Identical requests are cached in Redis. When the same prompt is sent again,
            the cached response is returned instantly with zero API cost.
        </p>
        
        <h3>2. Smart Routing</h3>
        <p>
            The proxy analyzes each request and automatically routes simple queries to GPT-3.5:
        </p>
        <ul class="feature-list">
            <li>Short prompts (&lt;50 characters)</li>
            <li>Simple questions (What is, How do, etc.)</li>
            <li>Translations</li>
            <li>Basic math/factual queries</li>
        </ul>
        <p>
            GPT-3.5 costs 90% less than GPT-4, with no quality loss for simple tasks.
        </p>
        
        <h3>3. Transparent</h3>
        <p>
            The proxy passes through all OpenAI API responses unchanged. Your application
            receives the exact same response format - no code changes needed.
        </p>
        
        <div class="warning">
            <strong>‚ö†Ô∏è Production Deployment:</strong> For production use, deploy the proxy
            to a hosted service (Railway, Render, Fly.io) and update the <code>base_url</code>
            to your deployed URL.
        </div>
        
        <h2>üìà Expected Savings</h2>
        
        <table style="width: 100%; border-collapse: collapse; margin: 20px 0;">
            <tr style="background: #f8f9fa;">
                <th style="padding: 15px; text-align: left; border-bottom: 2px solid #ddd;">Optimization</th>
                <th style="padding: 15px; text-align: left; border-bottom: 2px solid #ddd;">Typical Savings</th>
            </tr>
            <tr>
                <td style="padding: 15px; border-bottom: 1px solid #eee;">Caching duplicates</td>
                <td style="padding: 15px; border-bottom: 1px solid #eee; color: #4CAF50; font-weight: bold;">20-40%</td>
            </tr>
            <tr>
                <td style="padding: 15px; border-bottom: 1px solid #eee;">Model routing</td>
                <td style="padding: 15px; border-bottom: 1px solid #eee; color: #4CAF50; font-weight: bold;">10-30%</td>
            </tr>
            <tr>
                <td style="padding: 15px; border-bottom: 1px solid #eee;"><strong>Combined</strong></td>
                <td style="padding: 15px; border-bottom: 1px solid #eee; color: #4CAF50; font-weight: bold;"><strong>30-50%</strong></td>
            </tr>
        </table>
        
        <h2>üîß Troubleshooting</h2>
        
        <h3>Proxy won't start</h3>
        <ul style="margin-left: 20px; color: #666;">
            <li>Make sure Redis is running: <code>redis-cli ping</code> should return "PONG"</li>
            <li>Check that port 8000 is available</li>
            <li>Verify your OpenAI API key is set</li>
        </ul>
        
        <h3>Not seeing savings</h3>
        <ul style="margin-left: 20px; color: #666;">
            <li>Cache needs time to build - savings increase over time</li>
            <li>Most effective with repeated queries or patterns</li>
            <li>Check the live dashboard to verify proxy is receiving requests</li>
        </ul>
        
        <h2>üìß Support</h2>
        <p>
            Questions or issues? Open an issue on 
            <a href="https://github.com/yourusername/inference-optimizer" style="color: #667eea;">GitHub</a>
            or reach out directly.
        </p>
    </div>
</body>
</html>